{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask White Yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hls(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_white_yellow(image):\n",
    "    converted = convert_hls(image)\n",
    "    lower = np.uint8([  0, 200,   0])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(converted, lower, upper)\n",
    "    lower = np.uint8([ 10,   0, 100])\n",
    "    upper = np.uint8([ 40, 255, 255])\n",
    "    yellow_mask = cv2.inRange(converted, lower, upper)\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    whiteYellowImage = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return whiteYellowImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BGR to Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI : 관심영역 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "            \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "        \n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 2\n",
    "theta = np.pi/180\n",
    "threshold = 100\n",
    "min_line_length = 100\n",
    "max_line_gap = 100\n",
    "\n",
    "#houghLines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "#hough = cv2.HoughLinesP(img, 2, np.pi / 180, 100, np.array([]), minLineLength = 100, maxLineGap = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, a=0.8, b=1., c=0.):\n",
    "    return cv2.addWeighted(initial_img, a, img, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread('../test/test_img.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "capture = cv2.VideoCapture(\"../test/outside_clockwise.avi\")\n",
    "\n",
    "while True:    \n",
    "    ret, img = capture.read()\n",
    "    img_w = 720#img.shape[0]\n",
    "    img_h = 380#img.shape[1]\n",
    "    img = cv2.resize(img,(img_w,img_h))\n",
    "\n",
    "    ori_img = img\n",
    "\n",
    "    img = mask_white_yellow(img)\n",
    "    img = grayscale(img)\n",
    "    img = gaussian_blur(img, 5)\n",
    "    img = canny(img,40,80)\n",
    "    \n",
    "    yTopMask = img_h*0.55\n",
    "\n",
    "    vertices = np.array([[0, img_h], [0, img_h*0.75], [img_w, img_h*0.75], [img_w,img_h]], np.int32)\n",
    "\n",
    "    img = region_of_interest(img, [vertices])\n",
    "\n",
    "    #houghLines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "    hough = cv2.HoughLinesP(img, 2, np.pi / 180, 100, np.array([]), minLineLength = 100, maxLineGap = 50)\n",
    "    \n",
    "    foundLinesImage = np.zeros((img_h, img_w, 3), dtype=np.uint8)\n",
    "    \n",
    "    for line in hough:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(foundLinesImage, (x1, y1), (x2, y2), [255, 0, 0], 7)\n",
    "\n",
    "    origWithFoundLanes = weighted_img(foundLinesImage,ori_img)\n",
    "    \n",
    "    cv2.imshow('image',origWithFoundLanes)\n",
    "    \n",
    "    if cv2.waitKey(33) > 0: break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
