{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask White Yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hls(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_white_yellow(image):\n",
    "    converted = convert_hls(image)\n",
    "    lower = np.uint8([  0, 200,   0])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(converted, lower, upper)\n",
    "    lower = np.uint8([ 10,   0, 100])\n",
    "    upper = np.uint8([ 40, 255, 255])\n",
    "    yellow_mask = cv2.inRange(converted, lower, upper)\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    whiteYellowImage = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return whiteYellowImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BGR to Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(img, low_threshold, high_threshold):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI : 관심영역 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "            \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "        \n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, a=0.8, b=1., c=0.):\n",
    "    return cv2.addWeighted(initial_img, a, img, b, c)\n",
    "\n",
    "def draw_lines(img, line, color=[0, 0, 255], thickness=10): # 선 그리기\n",
    "    #for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "def average_lane(lane_data):\n",
    "    x1s = []\n",
    "    y1s = []\n",
    "    x2s = []\n",
    "    y2s = []\n",
    "    for data in lane_data:\n",
    "        x1s.append(data[0][0])\n",
    "        y1s.append(data[0][1])\n",
    "        x2s.append(data[0][2])\n",
    "        y2s.append(data[0][3])\n",
    "    \n",
    "    if np.isnan(np.mean(x1s)):\n",
    "        x1 = np.nan_to_num(np.mean(x1s))\n",
    "    else:\n",
    "        x1 = np.mean(x1s)\n",
    "    if np.isnan(np.mean(x2s)):\n",
    "        x2 = np.nan_to_num(np.mean(x2s))\n",
    "    else:\n",
    "        x2 = np.mean(x2s)\n",
    "    if np.isnan(np.mean(y1s)):\n",
    "        y1 = np.nan_to_num(np.mean(y1s))\n",
    "    else:\n",
    "        y1 = np.mean(y1s)\n",
    "    if np.isnan(np.mean(y2s)):\n",
    "        y2 = np.nan_to_num(np.mean(y2s))\n",
    "    else:\n",
    "        y2 = np.mean(y2s)\n",
    "    \n",
    "    return int(x1), int(y1), int(x2), int(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(img,src,dst):\n",
    "    \"\"\"\n",
    "    Execute perspective transform\n",
    "    \"\"\"\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    m = cv2.getPerspectiveTransform(src, dst)\n",
    "    m_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    warped = cv2.warpPerspective(img, m, img_size, flags=cv2.INTER_LINEAR)\n",
    "    unwarped = cv2.warpPerspective(warped, m_inv, (warped.shape[1], warped.shape[0]), flags=cv2.INTER_LINEAR)  # DEBUG\n",
    "\n",
    "    return warped, unwarped, m, m_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "\n",
    "class LaneTracker:\n",
    "    def __init__(self, n_lanes, proc_noise_scale, meas_noise_scale, process_cov_parallel=0, proc_noise_type='white'):\n",
    "        self.n_lanes = n_lanes\n",
    "        self.meas_size = 4 * self.n_lanes\n",
    "        self.state_size = self.meas_size * 2\n",
    "        self.contr_size = 0\n",
    "\n",
    "        self.kf = cv2.KalmanFilter(self.state_size, self.meas_size, self.contr_size)\n",
    "        self.kf.transitionMatrix = np.eye(self.state_size, dtype=np.float32)\n",
    "        self.kf.measurementMatrix = np.zeros((self.meas_size, self.state_size), np.float32)\n",
    "        for i in range(self.meas_size):\n",
    "            self.kf.measurementMatrix[i, i*2] = 1\n",
    "\n",
    "        if proc_noise_type == 'white':\n",
    "            block = np.matrix([[0.25, 0.5],\n",
    "                               [0.5, 1.]], dtype=np.float32)\n",
    "            self.kf.processNoiseCov = block_diag(*([block] * self.meas_size)) * proc_noise_scale\n",
    "        if proc_noise_type == 'identity':\n",
    "            self.kf.processNoiseCov = np.eye(self.state_size, dtype=np.float32) * proc_noise_scale\n",
    "        for i in range(0, self.meas_size, 2):\n",
    "            for j in range(1, self.n_lanes):\n",
    "                self.kf.processNoiseCov[i, i+(j*8)] = process_cov_parallel\n",
    "                self.kf.processNoiseCov[i+(j*8), i] = process_cov_parallel\n",
    "\n",
    "        self.kf.measurementNoiseCov = np.eye(self.meas_size, dtype=np.float32) * meas_noise_scale\n",
    "\n",
    "        self.kf.errorCovPre = np.eye(self.state_size)\n",
    "\n",
    "        self.meas = np.zeros((self.meas_size, 1), np.float32)\n",
    "        self.state = np.zeros((self.state_size, 1), np.float32)\n",
    "\n",
    "        self.first_detected = False\n",
    "\n",
    "    def _update_dt(self, dt):\n",
    "        for i in range(0, self.state_size, 2):\n",
    "            self.kf.transitionMatrix[i, i+1] = dt\n",
    "\n",
    "    def _first_detect(self, lanes):\n",
    "        for l, i in zip(lanes, range(0, self.state_size, 8)):\n",
    "            self.state[i:i+8:2, 0] = l\n",
    "        self.kf.statePost = self.state\n",
    "        self.first_detected = True\n",
    "\n",
    "    def update(self, lanes):\n",
    "        if self.first_detected:\n",
    "            for l, i in zip(lanes, range(0, self.meas_size, 4)):\n",
    "                if l is not None:\n",
    "                    self.meas[i:i+4, 0] = l\n",
    "            self.kf.correct(self.meas)\n",
    "        else:\n",
    "            if lanes.count is not None:\n",
    "                self._first_detect(lanes)\n",
    "\n",
    "    def predict(self, dt):\n",
    "        if self.first_detected:\n",
    "            self._update_dt(dt)\n",
    "            state = self.kf.predict()\n",
    "            lanes = []\n",
    "            for i in range(0, len(state), 8):\n",
    "                lanes.append((state[i], state[i+2], state[i+4], state[i+6]))\n",
    "            return lanes\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lt = LaneTracker(2, 0.1, 500)\n",
    "ticks = 0\n",
    "\n",
    "capture = cv2.VideoCapture(\"../test/outside_clockwise.avi\")\n",
    "#capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:    \n",
    "    ret, img = capture.read()\n",
    "    \n",
    "    img_w = 720#img.shape[0]\n",
    "    img_h = 380#img.shape[1]\n",
    "    img = cv2.resize(img,(img_w,img_h))\n",
    "\n",
    "    ori_img = img\n",
    "    \n",
    "    src = np.float32([[img_w*0.2, img_h*0.5],[0, img_h],[img_w, img_h*0.5], [img_w,img_h]])\n",
    "    dst = np.float32([[0, img_h*0.5],[0, img_h],[img_w, img_h*0.5], [img_w,img_h]])\n",
    "    \n",
    "    img = mask_white_yellow(img)\n",
    "    img = grayscale(img)\n",
    "    img = gaussian_blur(img, 5)\n",
    "    img = canny(img,40,80)\n",
    "    \n",
    "    warped, unwarped, m, m_inv = perspective_transform(ori_img,src,dst)\n",
    "    \n",
    "    yTopMask = img_h*0.55\n",
    "    \n",
    "    pts = np.array([[0, img_h], [img_w*0.2, img_h*0.6], [img_w*0.8, img_h*0.6], [img_w,img_h]])\n",
    "    #pts = [[0, img_h],[img_w, 0],[img_w, 0],[img_w, img_h]]\n",
    "    vertices = np.array(pts, np.int32)\n",
    "    \n",
    "    img = region_of_interest(img, [vertices])\n",
    "    \n",
    "    #houghLines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "    hough = cv2.HoughLinesP(img, 2, np.pi / 180, 100, np.array([]), minLineLength = 100, maxLineGap = 50)\n",
    "    \n",
    "    if hough is not None:\n",
    "        line_arr = np.squeeze(hough,axis=1)\n",
    "        \n",
    "        slope_degree = (np.arctan2(line_arr[:,1] - line_arr[:,3], line_arr[:,0] - line_arr[:,2]) * 180) / np.pi\n",
    "\n",
    "        # 수평 기울기 제한\n",
    "        line_arr = line_arr[np.abs(slope_degree)<160]\n",
    "        slope_degree = slope_degree[np.abs(slope_degree)<160]\n",
    "        # 수직 기울기 제한\n",
    "        line_arr = line_arr[np.abs(slope_degree)>95]\n",
    "        slope_degree = slope_degree[np.abs(slope_degree)>95]\n",
    "        # 필터링된 직선 버리기\n",
    "        L_lines, R_lines = line_arr[(slope_degree>0),:], line_arr[(slope_degree<0),:]\n",
    "        temp = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "        L_lines, R_lines = L_lines[:,None], R_lines[:,None]\n",
    "\n",
    "        foundLinesImage = np.zeros((img_h, img_w, 3), dtype=np.uint8)\n",
    "        #foundLinesImage = np.zeros((img_h, img_w), dtype=np.uint8)\n",
    "        \n",
    "        if L_lines is not None:\n",
    "            L_line = np.array([average_lane(L_lines)])\n",
    "            #draw_lines(foundLinesImage,L_line)\n",
    "        if R_lines is not None:\n",
    "            R_line = np.array([average_lane(R_lines)])\n",
    "            #draw_lines(foundLinesImage,R_line)\n",
    "        '''\n",
    "        precTick = ticks\n",
    "        ticks = cv2.getTickCount()\n",
    "        dt = (ticks - precTick) / cv2.getTickFrequency()\n",
    "        \n",
    "        predicted = lt.predict(dt)\n",
    "        \n",
    "        if predicted is not None:\n",
    "            cv2.line(foundLinesImage, (predicted[0][0], predicted[0][1]), (predicted[0][2], predicted[0][3]), (0, 0, 255), 5)\n",
    "            cv2.line(foundLinesImage, (predicted[1][0], predicted[1][1]), (predicted[1][2], predicted[1][3]), (0, 0, 255), 5)\n",
    "\n",
    "        lt.update([L_line,R_line])\n",
    "        '''\n",
    "        \n",
    "        origWithFoundLanes = weighted_img(foundLinesImage,ori_img)\n",
    "        \n",
    "    else:\n",
    "        origWithFoundLanes = ori_img\n",
    "    \n",
    "    cv2.imshow('image',origWithFoundLanes)\n",
    "    cv2.imshow('warp',warped)\n",
    "    cv2.imshow('unwarp',unwarped)\n",
    "    \n",
    "    if cv2.waitKey(33) > 0: break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
